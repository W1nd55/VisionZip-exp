
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.1.2 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/tools/mme_run_all.py", line 15, in <module>
    from scripts.metric import MMEAcc, MMEAccPlus, DelayStats
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/metric.py", line 4, in <module>
    from scripts.abstract import BaseMetric, Sample
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/abstract.py", line 4, in <module>
    import torch
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/__init__.py", line 1382, in <module>
    from .functional import *  # noqa: F403
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/functional.py", line 7, in <module>
    import torch.nn.functional as F
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
Traceback (most recent call last):
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/tools/mme_ann_builder.py", line 217, in <module>
    main()
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/tools/mme_ann_builder.py", line 203, in main
    raise FileNotFoundError(f"No annotation file found in {subdir}. Please put qa.json / questions.json / annotation.json etc.")
FileNotFoundError: No annotation file found in /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/datasets/mme/MME_Benchmark_release_version/MME_Benchmark/OCR. Please put qa.json / questions.json / annotation.json etc.
[build] Found 20 txt files under /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/datasets/mme/MME_Benchmark_release_version/MME_Benchmark/OCR (pattern=**/*.txt)
[build] Built 20 items, missed_img=0, bad_txt=0
[build] Saved to /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/ann/ann_mme_OCR.json

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.1.2 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/evalkit.py", line 6, in <module>
    import torch
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/__init__.py", line 1382, in <module>
    from .functional import *  # noqa: F403
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/functional.py", line 7, in <module>
    import torch.nn.functional as F
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/__init__.py", line 35, in <module>
    from .transformer import TransformerEncoder, TransformerDecoder, \
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 20, in <module>
    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)
  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),
/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2025-11-30 07:14:36,488 - llava.model.builder - INFO - Start Sparse Inference...
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
[load] using pure fp16 on single GPU ...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.58it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 12.56it/s]
[load] fp16 load success
[load] model moved to cuda
[Eval] Warmup 3 samples ...
Traceback (most recent call last):
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 182, in convert_to_tensors
    tensor = as_tensor(value)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 141, in as_tensor
    return torch.tensor(value)
RuntimeError: Could not infer dtype of numpy.float32

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/model.py", line 175, in prepare_inputs
    bf = self.image_processor(images=[img], return_tensors='pt')
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/image_processing_utils.py", line 552, in __call__
    return self.preprocess(images, **kwargs)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/models/clip/image_processing_clip.py", line 326, in preprocess
    return BatchFeature(data=data, tensor_type=return_tensors)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 78, in __init__
    self.convert_to_tensors(tensor_type=tensor_type)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 188, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 182, in convert_to_tensors
    tensor = as_tensor(value)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 141, in as_tensor
    return torch.tensor(value)
RuntimeError: Could not infer dtype of numpy.float32

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/evalkit.py", line 255, in <module>
    evaluator.run(limit=limit)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/evaluate.py", line 48, in run
    inputs = self.model.prepare_inputs(s)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/model.py", line 178, in prepare_inputs
    bf = self.image_processor.preprocess([img], return_tensors='pt')
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/models/clip/image_processing_clip.py", line 326, in preprocess
    return BatchFeature(data=data, tensor_type=return_tensors)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 78, in __init__
    self.convert_to_tensors(tensor_type=tensor_type)
  File "/home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/lib/python3.10/site-packages/transformers/feature_extraction_utils.py", line 188, in convert_to_tensors
    raise ValueError(
ValueError: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.
[info] subtasks: ['OCR']

=== MME Subtask: OCR ===
[build-primary] /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/bin/python3 /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/tools/mme_ann_builder.py --mme_root /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/datasets/mme/MME_Benchmark_release_version/MME_Benchmark --subtask OCR --out /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/ann/ann_mme_OCR.json
[build-primary] failed rc=1
[build-txtpairs] /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/bin/python3 /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/tools/mme_ann_from_txtpairs.py --subtask_dir /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/datasets/mme/MME_Benchmark_release_version/MME_Benchmark/OCR --qa_glob **/*.txt --out /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/ann/ann_mme_OCR.json
[flatten] flattened -> /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/ann/ann_mme_OCR.json (40 items, with meta.image_id/pair)
[eval] /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/env_sparsezip/bin/python3 /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/scripts/evalkit.py --cfg /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/config/llava_mme.yaml --ann_path /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/ann/ann_mme_OCR.json --output_dir /home/w1nd519994824/project/mittalshivam003/VisionZip-exp/runs/smoke/mme_llava/results/outputs_OCR --limit 20
[error] OCR evaluation failed: returncode=1

=== Summarizing ===
[warn] No results to summarize
